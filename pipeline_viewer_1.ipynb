{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe91dc6-cd11-4d0c-93e4-5ecbc25a3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import networkx as nx\n",
    "import time\n",
    "import heapq\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from sys import platform\n",
    "import time\n",
    "!chmod +x spike-dasm.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "99bb1677-3365-4b67-be85-06b78e537a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON\n",
    "with open('hello.out', 'r') as f:\n",
    "    json_lines = f.readlines()\n",
    "\n",
    "inst_jsons = []\n",
    "for line in json_lines:\n",
    "    try:\n",
    "        inst_jsons.append(json.loads(line))\n",
    "    except json.JSONDecodeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6ce2027d-c05a-4e95-a192-5b6b81a8c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_names = [\"IF1\", \"IF2\", \"IBuf\", \"EX\", \"MEM\", \"DIV\", \"WB\", \"LLWB\", \"COM\", \"RET\", \"DIV WB\"]\n",
    "start_stage = \"IF1\"\n",
    "end_stages = [\"RET\", \"LLWB\"]\n",
    "event_types = [\"bytes\", \"pc\", \"bytes\", \"inst_bytes\", \"bytes\", \"bytes\", \"bytes\", \"bytes\", \"bytes\", \"bytes\", \"bytes\"]\n",
    "event_to_datatype = {e:d for e, d in zip(event_names, event_types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2175508c-e9bc-49b8-8cce-50636d3d63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_array(jsons):\n",
    "    dasm_input = \"\"\n",
    "    for json in jsons:\n",
    "        if event_to_datatype[json[\"event_name\"]] == \"inst_bytes\":\n",
    "            dasm_input += \"DASM(\" + json[\"data\"] + \")|\"\n",
    "        else:\n",
    "            dasm_input += json[\"data\"] + \"|\"\n",
    "    dasm_input = dasm_input[:-1]\n",
    "    if platform == \"darwin\":\n",
    "        p = Popen(\"./spike-dasm --isa=rv64gcv\", stdout=PIPE, stdin=PIPE, stderr=PIPE, text=True, shell=True)\n",
    "    else:\n",
    "        p = Popen(\"./spike-dasm.exe --isa=rv64gcv\", stdout=PIPE, stdin=PIPE, stderr=PIPE, text=True, shell=True)\n",
    "    stdout_data = p.communicate(input=dasm_input)[0]\n",
    "    insts = stdout_data.split(\"|\")\n",
    "    return np.array(insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "23883804-1914-4498-b134-d096230e3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_ids = np.array([inst_jsons[i][\"id\"] for i in range(len(inst_jsons))])\n",
    "inst_cycle = np.array([inst_jsons[i][\"cycle\"].strip() for i in range(len(inst_jsons))])\n",
    "inst_event = np.array([inst_jsons[i][\"event_name\"] for i in range(len(inst_jsons))])\n",
    "data_field = generate_data_array(inst_jsons)\n",
    "inst_parent = np.array([inst_jsons[i][\"parents\"] for i in range(len(inst_jsons))])\n",
    "data = np.column_stack((inst_ids,inst_parent, inst_cycle, inst_event, data_field))\n",
    "columns = [\"inst_id\", \"parent_id\", \"cycle\", \"stage\", \"data\"]\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5f0b8d80-6305-4bb2-b413-68bd39d6874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>stage</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140044</th>\n",
       "      <td>0x00000001000221be</td>\n",
       "      <td>0x00000000000221bd</td>\n",
       "      <td>139710</td>\n",
       "      <td>IF2</td>\n",
       "      <td>0x0080000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   inst_id           parent_id   cycle stage          data\n",
       "140044  0x00000001000221be  0x00000000000221bd  139710   IF2  0x0080000000"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"parent_id\"] == \"0x00000000000221bd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "db2b1c0b-4d53-4121-9519-daf96e2d38ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>stage</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140047</th>\n",
       "      <td>0x00000004000221bf</td>\n",
       "      <td>0x00000001000221be</td>\n",
       "      <td>139711</td>\n",
       "      <td>EX</td>\n",
       "      <td>li      ra, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140048</th>\n",
       "      <td>0x00000002000221bf</td>\n",
       "      <td>0x00000001000221be</td>\n",
       "      <td>139711</td>\n",
       "      <td>IBuf</td>\n",
       "      <td>0x0080000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   inst_id           parent_id   cycle stage           data\n",
       "140047  0x00000004000221bf  0x00000001000221be  139711    EX  li      ra, 0\n",
       "140048  0x00000002000221bf  0x00000001000221be  139711  IBuf   0x0080000002"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"parent_id\"] == \"0x00000001000221be\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b1c13-fb77-43ad-8515-4a0e45b6cb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5ab1b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global id\n",
    "id = 0\n",
    "def construct_graph(df):\n",
    "    DG = nx.DiGraph()\n",
    "    for row in df.itertuples():\n",
    "        DG.add_node(row.inst_id, cycle=row.cycle, data=row.data, stage=row.stage)\n",
    "        if row.parent_id != \"None\":\n",
    "            DG.add_edge(row.parent_id, row.inst_id)\n",
    "    return DG            \n",
    "def construct_speculative_trace(G):\n",
    "    paths = []\n",
    "    id = 0\n",
    "    for node in G:\n",
    "        data = G.nodes[node]\n",
    "        if G.in_degree(node) == 0: # root node\n",
    "            new_paths = trace_down(G, node, [], [])\n",
    "            paths.extend(new_paths)\n",
    "    for path in paths:\n",
    "        if path[-1][0] not in end_stages:\n",
    "            path.append((\"FLUSH\", str(int(path[-1][1]) + 1), \"None\"))\n",
    "        else:\n",
    "            path.append((\"KONNATA_RET\", str(int(path[-1][1]) + 1), \"None\"))\n",
    "        path.insert(0, (id, path[0][-1]))\n",
    "    return paths\n",
    "\n",
    "def trace_down(G, node, curr_path, paths):\n",
    "    id = id + 1\n",
    "    data = G.nodes[node]\n",
    "    curr_path.append((data[\"stage\"], data[\"cycle\"], data[\"data\"]))\n",
    "    if G.out_degree(node) == 0: # terminal node\n",
    "        paths.append(curr_path)\n",
    "        return paths\n",
    "    succs = list(DG.successors(node))\n",
    "    if data[\"stage\"] not in split_points and len(succs) > 1:\n",
    "        inst_paths = [trace_down(G, n, [], [])[0] for n in succs]\n",
    "        inst_paths = inst_paths[1] + inst_paths[0]\n",
    "        inst_paths.sort(key=lambda x: x[1])\n",
    "        paths.append(curr_path + inst_paths)\n",
    "    for n in succs:\n",
    "        if n == sucs[0]:\n",
    "            paths.extend(trace_down(G, n, curr_path[:], []))\n",
    "        else:\n",
    "            paths.extend(trace_down(G, n, [(\"DEP\", cycle, )], []))\n",
    "    return paths\n",
    "\n",
    "def construct_committed_trace(G):\n",
    "    paths = []\n",
    "    id = 0\n",
    "    for node in G:\n",
    "        data = G.nodes[node]\n",
    "        if G.out_degree(node) == 0 and data[\"stage\"] in end_stages: # committed leaf node\n",
    "            new_path = trace_up(G, node)\n",
    "            new_path.insert(0, (id, data[\"data\"]))\n",
    "            paths.append(new_path)\n",
    "            id += 1\n",
    "    return paths\n",
    "\n",
    "def trace_up(G, node):\n",
    "    path = []\n",
    "    while node:\n",
    "        data = G.nodes[node]\n",
    "        path.insert(0, (data[\"stage\"], data[\"cycle\"], data[\"data\"]))\n",
    "        node = list(DG.predecessors(node))[0] if list(DG.predecessors(node)) else \"\"\n",
    "    return path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "76cf336e-1f59-4c93-b3d2-6ad450acd516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionTracer:\n",
    "    def __init__(self, df):\n",
    "        self.id = 0\n",
    "        self.G = nx.DiGraph()\n",
    "        for row in df.itertuples():\n",
    "            self.G.add_node(row.inst_id, cycle=row.cycle, data=row.data, stage=row.stage)\n",
    "            if row.parent_id != \"None\":\n",
    "                self.G.add_edge(row.parent_id, row.inst_id)\n",
    "\n",
    "    def construct_speculative_trace(self):\n",
    "        self.id = 0\n",
    "        paths = []\n",
    "        for node in self.G:\n",
    "            data = self.G.nodes[node]\n",
    "            if self.G.in_degree(node) == 0: # root node\n",
    "                new_paths = self.trace_down(node, [self.id], [])\n",
    "                self.id += 1\n",
    "                paths.extend(new_paths)\n",
    "        for path in paths:\n",
    "            if path[-1][0] not in end_stages:\n",
    "                path.append((\"FLUSH\", int(path[-1][1]) + 1, \"None\"))\n",
    "            else:\n",
    "                path.append((\"KONNATA_RET\", int(path[-1][1]) + 1, \"None\"))\n",
    "        return paths\n",
    "\n",
    "    def trace_down(self, node, curr_path, paths):\n",
    "        data = self.G.nodes[node]\n",
    "        curr_path.append((data[\"stage\"], int(data[\"cycle\"]), data[\"data\"]))\n",
    "        if self.G.out_degree(node) == 0: # terminal node\n",
    "            paths.append(curr_path)\n",
    "            return paths\n",
    "        succs = list(self.G.successors(node))\n",
    "        # if data[\"stage\"] not in split_points and len(succs) > 1:\n",
    "        #     inst_paths = [self.trace_down(n, [], [])[0] for n in succs]\n",
    "        #     inst_paths = inst_paths[1] + inst_paths[0]\n",
    "        #     inst_paths.sort(key=lambda x: x[1])\n",
    "        #     paths.append(curr_path + inst_paths)\n",
    "        for n in succs:\n",
    "            if n == succs[0]:\n",
    "                paths.extend(self.trace_down(n, curr_path[:], []))\n",
    "            else:\n",
    "                self.id += 1\n",
    "                paths.extend(self.trace_down(n, [self.id, (\"DEP\", int(data[\"cycle\"]), str(curr_path[0]))], []))\n",
    "        return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3547b799-9016-4190-95bc-8e16edfe1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = InstructionTracer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ebd4ba04-424a-4774-a5d0-06992d214938",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = tracer.construct_speculative_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a0bde9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def convert_to_kanata(threads, verbose=False):\n",
    "    pq = []\n",
    "    if not verbose:\n",
    "        threads = list(filter(lambda x: x[-1][0] == 'KONNATA_RET', threads)) #Relies on the last element of inst list being RET\n",
    "    for inst in threads:\n",
    "        id = inst[0]\n",
    "        for stage in inst[1:]:\n",
    "            heapq.heappush(pq, ((int(stage[1])), (id, stage[2], stage[0]))) #Min heap of (cycle -> (unique_id, pc, pipeline stage))\n",
    "            \n",
    "    with open('hello.log', 'w') as file:\n",
    "        file.write('Kanata    0004\\n')\n",
    "        cycle, (id, pc, stage) = heapq.heappop(pq)\n",
    "        prev_cycle = cycle\n",
    "        file.write(f'C=\\t{cycle}\\n')\n",
    "        while pq:\n",
    "            cycle_diff = cycle - prev_cycle\n",
    "            if (cycle_diff > 0):\n",
    "                file.write(f\"C\\t{cycle_diff}\\n\")\n",
    "            if (stage == start_stage):\n",
    "                file.write(f\"I\\t{id}\\t{cycle}\\t0\\n\")\n",
    "                # file.write(f\"L    {id}    0    {pc}\\n\")\n",
    "            if (stage == 'KONNATA_RET'):\n",
    "                file.write(f\"R\\t{id}\\t{id}\\t0\\n\")\n",
    "            elif (stage == 'DEP'):\n",
    "                # spawn new row and draw dependency between this row and next\n",
    "                file.write(f\"I\\t{id}\\t{cycle}\\t0\\n\")\n",
    "                file.write(f\"W\\t{id}\\t{int(pc)}\\t1\\n\")\n",
    "            elif (stage == 'FLUSH'):\n",
    "                file.write(f\"R\\t{id}\\t{id}\\t1\\n\")\n",
    "            elif (event_to_datatype[stage] == \"inst_bytes\"):\n",
    "                file.write(f\"S\\t{id}\\t0\\t{stage}\\n\")\n",
    "                file.write(f\"L\\t{id}\\t0\\tDASM:{pc}\\n\")\n",
    "            elif (event_to_datatype[stage] == \"pc\"):\n",
    "                file.write(f\"S\\t{id}\\t0\\t{stage}\\n\")\n",
    "                file.write(f\"L\\t{id}\\t0\\tPC:{pc} \\n\")\n",
    "            else:\n",
    "                file.write(f\"S\\t{id}\\t0\\t{stage}\\n\")\n",
    "                file.write(f\"L\\t{id}\\t1\\tPC:{pc}\\n\")\n",
    "\n",
    "            prev_cycle = cycle\n",
    "            cycle, (id, pc, stage) = heapq.heappop(pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ffe44ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_kanata(paths, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac62457-2c9e-4631-a7a3-4102d8f80c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a51c1-5e03-485e-9810-d585b96c1335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
